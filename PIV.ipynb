{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Function that returns the configuration dictionary with all parameters used in processing\n",
    "def get_config():\n",
    "    return {\n",
    "        'video_paths': '/Users/Ricardo/Desktop/Y4 Lab code/All Videos 10',  # Input videos directory\n",
    "        'output_directory': '/Users/Ricardo/Desktop/Y4 Lab code/PIV_2/videos',  # Output processed videos directory\n",
    "        'csv_output_directory': '/Users/Ricardo/Desktop/Y4 Lab code/PIV_2/csv',  # Output CSV directory\n",
    "        'start_frame': 11,  # Starting frame index for processing\n",
    "        'end_frame': 300,   # Ending frame index for processing\n",
    "        'window_size': (200, 200),  # Size of interrogation window for PIV\n",
    "        'x_range': (0, 200),  # X-axis range for splitting windows\n",
    "        'y_ranges': [(220, 420), (420, 620), (620, 820)],  # Multiple Y ranges for splitting windows\n",
    "        'gaussian_blur_kernel_size': (13, 13),  # Kernel size for Gaussian blur applied to frames\n",
    "        'arrow_params': {'color': (0, 0, 0), 'thickness': 2, 'tip_length': 0.1},  # Arrow drawing params\n",
    "        'video_codec': 'MJPG',  # Codec for output video\n",
    "        'target_height': 1080,  # Target resolution height (not used in current version)\n",
    "        'scale_factor': 50,  # Scale factor applied to displacement vectors\n",
    "        'heatmap_colormap': cv2.COLORMAP_JET,  # Colour map for heatmap visualisation\n",
    "        'time_averaging_window_size': 1  # Number of frames used for temporal averaging\n",
    "    }\n",
    "\n",
    "# Recursively search directory for video files and group them by subfolder\n",
    "def get_video_paths(input_directory):\n",
    "    video_paths = {}\n",
    "    for subdir, _, files in os.walk(input_directory):\n",
    "        video_files = [filename for filename in files if filename.endswith('.mp4')]\n",
    "        if video_files:\n",
    "            folder_name = os.path.basename(subdir)\n",
    "            video_paths[folder_name] = [os.path.join(subdir, filename) for filename in video_files]\n",
    "    return video_paths\n",
    "\n",
    "# Split a frame into smaller windows of given size, restricted to x and y ranges\n",
    "def split_window(frame, window_size, x_range, y_range):\n",
    "    return [((x + window_size[0] // 2, y + window_size[1] // 2), \n",
    "             frame[y:y + window_size[1], x:x + window_size[0]])\n",
    "            for x in range(x_range[0], x_range[1], window_size[0])\n",
    "            for y in range(y_range[0], y_range[1], window_size[1])\n",
    "            if frame[y:y + window_size[1], x:x + window_size[0]].shape == window_size]\n",
    "\n",
    "# Perform FFT-based cross-correlation between two interrogation windows\n",
    "def fft_correlate_images(w1, w2):\n",
    "    return np.abs(np.fft.fftshift(np.fft.ifft2(np.fft.fft2(w2) * np.conj(np.fft.fft2(w1)))))\n",
    "\n",
    "# Subpixel peak estimation using quadratic interpolation around the correlation peak\n",
    "def subpixel_peak_position_quad(shift, max_pos):\n",
    "    y0, x0 = max_pos\n",
    "    if x0 <= 0 or x0 >= shift.shape[1] - 1 or y0 <= 0 or y0 >= shift.shape[0] - 1:\n",
    "        return np.array([y0, x0])\n",
    "    # Extract correlation values around the peak\n",
    "    Cx_1, Cx0, Cx1 = shift[y0, x0-1], shift[y0, x0], shift[y0, x0+1]\n",
    "    Cy_1, Cy0, Cy1 = shift[y0-1, x0], shift[y0, x0], shift[y0+1, x0]\n",
    "    # Quadratic subpixel displacement estimation\n",
    "    dx = (Cx1 - Cx_1) / (2 * (2 * Cx0 - Cx_1 - Cx1)) if 2 * (2 * Cx0 - Cx_1 - Cx1) != 0 else 0\n",
    "    dy = (Cy1 - Cy_1) / (2 * (2 * Cy0 - Cy_1 - Cy1)) if 2 * (2 * Cy0 - Cy_1 - Cy1) != 0 else 0\n",
    "    return np.array([y0 + dy, x0 + dx])\n",
    "\n",
    "# Draw an arrow representing displacement vector on a frame\n",
    "def draw_arrow_on_frame(frame, x, y, u, v, arrow_params):\n",
    "    cv2.arrowedLine(frame, (int(x), int(y)), (int(x + u), int(y + v)),\n",
    "                    arrow_params['color'], arrow_params['thickness'],\n",
    "                    tipLength=arrow_params['tip_length'])\n",
    "\n",
    "# Apply heatmap colour mapping to a frame\n",
    "def apply_heatmap(frame, colormap):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    norm = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    heatmap = cv2.applyColorMap(norm, colormap)\n",
    "    return heatmap\n",
    "\n",
    "# Process all videos in a folder together, stacking them into a composite video with time-averaging\n",
    "def process_stacked_video(config, folder_video_paths, subdir_name):\n",
    "    # Open all videos in the folder\n",
    "    caps = [cv2.VideoCapture(path) for path in folder_video_paths]\n",
    "    caps = [cap for cap in caps if cap.isOpened()]\n",
    "    if not caps:\n",
    "        return\n",
    "\n",
    "    # Determine the minimum available number of frames across all videos\n",
    "    total_frames = min([int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) for cap in caps])\n",
    "    end_frame = config['end_frame'] if config['end_frame'] < total_frames else total_frames\n",
    "    start_frame = config['start_frame']\n",
    "\n",
    "    # Move to the start frame for each video\n",
    "    for cap in caps:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "    # Determine frame dimensions (assume all videos are the same size)\n",
    "    w = int(caps[0].get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = int(caps[0].get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Prepare output video writer and directories\n",
    "    output_video_name = f\"{subdir_name}_stacked.avi\"\n",
    "    fps = caps[0].get(cv2.CAP_PROP_FPS)\n",
    "    output_video_dir = os.path.join(config['output_directory'], subdir_name)\n",
    "    os.makedirs(output_video_dir, exist_ok=True)\n",
    "    output_csv_dir = os.path.join(config['csv_output_directory'], subdir_name)\n",
    "    os.makedirs(output_csv_dir, exist_ok=True)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*config['video_codec'])\n",
    "    out_video = cv2.VideoWriter(os.path.join(output_video_dir, output_video_name), fourcc, fps, (w, h))\n",
    "\n",
    "    csv_output_path = os.path.join(output_csv_dir, f\"{subdir_name}_stacked.csv\")\n",
    "    \n",
    "    # Buffers for temporal processing:\n",
    "    # 1. composite_buffer: used for time-averaging across several frames (displacement calculation)\n",
    "    # 2. raw_buffer: stores the un-averaged composite frames (for display/visualisation)\n",
    "    composite_buffer = []\n",
    "    raw_buffer = []\n",
    "    \n",
    "    with open(csv_output_path, 'w', newline=\"\") as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow(['frame_index', 'x', 'y', 'u', 'v'])  # Header row\n",
    "        \n",
    "        # Read the first composite frame by averaging across all videos\n",
    "        frames = []\n",
    "        for cap in caps:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frames.append(frame)\n",
    "        if len(frames) != len(caps):\n",
    "            return\n",
    "        composite = np.mean(frames, axis=0).astype(np.uint8)\n",
    "        composite_buffer.append(composite)\n",
    "        raw_buffer.append(composite)\n",
    "        \n",
    "        # Initialise variables for previous averaged composite and raw display frame\n",
    "        avg_composite_prev = None\n",
    "        raw_vis_prev = None\n",
    "        fidx = start_frame + 1  # start from the next frame\n",
    "\n",
    "        # Process frames until end_frame\n",
    "        while fidx < end_frame:\n",
    "            # Read next composite frame (average of all videos at the same index)\n",
    "            frames_next = []\n",
    "            for cap in caps:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                frames_next.append(frame)\n",
    "            if len(frames_next) != len(caps):\n",
    "                break\n",
    "            composite = np.mean(frames_next, axis=0).astype(np.uint8)\n",
    "            \n",
    "            # Append to buffers\n",
    "            composite_buffer.append(composite)\n",
    "            raw_buffer.append(composite)\n",
    "            # Keep buffers within window size\n",
    "            if len(composite_buffer) > config['time_averaging_window_size']:\n",
    "                composite_buffer.pop(0)\n",
    "            if len(raw_buffer) > config['time_averaging_window_size']:\n",
    "                raw_buffer.pop(0)\n",
    "            \n",
    "            # Skip until buffer is fully filled\n",
    "            if len(composite_buffer) < config['time_averaging_window_size']:\n",
    "                fidx += 1\n",
    "                continue\n",
    "            \n",
    "            # Compute time-averaged composite for displacement calculation\n",
    "            avg_composite_current = np.mean(np.array(composite_buffer), axis=0).astype(np.uint8)\n",
    "            \n",
    "            # If first time, initialise and continue\n",
    "            if avg_composite_prev is None:\n",
    "                avg_composite_prev = avg_composite_current\n",
    "                raw_vis_prev = raw_buffer[-1]  # Use newest raw frame for visualisation\n",
    "                fidx += 1\n",
    "                continue\n",
    "            \n",
    "            # Preprocess both averaged composite frames (Gaussian blur + grayscale)\n",
    "            f1g = cv2.GaussianBlur(cv2.cvtColor(avg_composite_prev, cv2.COLOR_BGR2GRAY),\n",
    "                                   config['gaussian_blur_kernel_size'], 0)\n",
    "            f2g = cv2.GaussianBlur(cv2.cvtColor(avg_composite_current, cv2.COLOR_BGR2GRAY),\n",
    "                                   config['gaussian_blur_kernel_size'], 0)\n",
    "            \n",
    "            # Split into interrogation windows\n",
    "            w1, w2 = [], []\n",
    "            for yr in config['y_ranges']:\n",
    "                w1.extend(split_window(f1g, config['window_size'], config['x_range'], yr))\n",
    "                w2.extend(split_window(f2g, config['window_size'], config['x_range'], yr))\n",
    "            \n",
    "            # Compute displacement vectors\n",
    "            averaged_displacements = []\n",
    "            for ((cx, cy), window1), ((_, _), window2) in zip(w1, w2):\n",
    "                shift = fft_correlate_images(window1, window2)\n",
    "                mxp = np.unravel_index(np.argmax(shift), shift.shape)\n",
    "                sp = subpixel_peak_position_quad(shift, mxp)\n",
    "                dx = sp[1] - shift.shape[1] // 2\n",
    "                dy = sp[0] - shift.shape[0] // 2\n",
    "                averaged_displacements.append(((cx, cy), (dx * config['scale_factor'], dy * config['scale_factor'])))\n",
    "            \n",
    "            # Visualisation: apply heatmap to raw (not averaged) composite frame\n",
    "            heat_frame = apply_heatmap(raw_vis_prev, config['heatmap_colormap'])\n",
    "            for (x, y), (u, v) in averaged_displacements:\n",
    "                draw_arrow_on_frame(heat_frame, x, y, u, v, config['arrow_params'])\n",
    "                csv_writer.writerow([fidx, x, y, u, v])\n",
    "            \n",
    "            # Save processed frame\n",
    "            out_video.write(heat_frame)\n",
    "            \n",
    "            # Update previous references\n",
    "            avg_composite_prev = avg_composite_current\n",
    "            raw_vis_prev = raw_buffer[-1]\n",
    "            fidx += 1\n",
    "\n",
    "    for cap in caps:\n",
    "        cap.release()\n",
    "    out_video.release()\n",
    "\n",
    "# Main script: prepares directories, loads videos, and processes each folder of videos\n",
    "def main():\n",
    "    config = get_config()\n",
    "    os.makedirs(config['output_directory'], exist_ok=True)\n",
    "    os.makedirs(config['csv_output_directory'], exist_ok=True)\n",
    "    video_paths = get_video_paths(config['video_paths'])\n",
    "    \n",
    "    if video_paths:\n",
    "        for subdir_name, video_files in video_paths.items():\n",
    "            # Process each folder into a stacked video with time-averaged composites\n",
    "            process_stacked_video(config, video_files, subdir_name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
